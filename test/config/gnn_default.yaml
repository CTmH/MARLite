agent_group_config:
  type: "GNN"
  agent_list:
    predator_0: model1
    predator_1: model1
    predator_2: model1
    predator_3: model1
    predator_4: model1
    predator_5: model1
    predator_6: model1
    predator_7: model1
    predator_8: model1
    predator_9: model1
    predator_10: model1
    predator_11: model1
    predator_12: model1
    predator_13: model1
    predator_14: model1
    predator_15: model1
    predator_16: model1
    predator_17: model1
    predator_18: model1
    predator_19: model1
    predator_20: model1
    predator_21: model1
    predator_22: model1
    predator_23: model1
    predator_24: model1
  model_configs:
    model1:
      feature_extractor:
        model_type: "Custom"
        layers:
        - type: ChannelSelector
          num_channels: [0, 1, 2, 3, 4]
        - type: Permute
          dims: [0, 3, 1, 2]
        - type: Conv2d
          in_channels: 5
          out_channels: 16
          kernel_size: 3
          stride: 1
          padding: 1
        - type: BatchNorm2d
          num_features: 16
        - type: ReLU
        - type: Conv2d
          in_channels: 16
          out_channels: 1
          kernel_size: 3
          stride: 1
          padding: 0
        - type: BatchNorm2d
          num_features: 1
        - type: ReLU
        - type: Flatten
      encoder:
        model_type: "CustomTimeSeq"
        layers:
        - type: Permute
          dims: [0, 2, 1]
        - type: Conv1d
          in_channels: 64
          out_channels: 32
          kernel_size: 3
          stride: 2
          padding: 0
        - type: Flatten
        - type: ReLU
      decoder:
        model_type: "Custom"
        layers:
        - type: Linear
          in_features: 64
          out_features: 13
  graph_builder_config:
    type: "Magent2"
    binary_agent_id_dim: [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
    agent_presence_dim: [3] # Predator: 3, Prey: 1 
    comm_distance: 10
    distance_metric: "cityblock"
  graph_model_config:
    model_type: "GCN"
    input_dim: 64
    hidden_dim: 64
    output_dim: 64
  optimizer:
    type: "Adam"
    lr: 0.0005
    weight_decay: 0.0001
  msg_dist: 5

env_config:
  module_name: "custom"
  env_name: "adversarial_pursuit_predator"
  tag_penalty: 0.0
  node_communication_distance: 10
  extra_features: true
  opponent_agent_group_config:
    type: "Random"
    agent_list:
      prey_0: random1
      prey_1: random1
      prey_2: random1
      prey_3: random1
      prey_4: random1
      prey_5: random1
      prey_6: random1
      prey_7: random1
      prey_8: random1
      prey_9: random1
      prey_10: random1
      prey_11: random1
      prey_12: random1
      prey_13: random1
      prey_14: random1
      prey_15: random1
      prey_16: random1
      prey_17: random1
      prey_18: random1
      prey_19: random1
      prey_20: random1
      prey_21: random1
      prey_22: random1
      prey_23: random1
      prey_24: random1
      prey_25: random1
      prey_26: random1
      prey_27: random1
      prey_28: random1
      prey_29: random1
      prey_30: random1
      prey_31: random1
      prey_32: random1
      prey_33: random1
      prey_34: random1
      prey_35: random1
      prey_36: random1
      prey_37: random1
      prey_38: random1
      prey_39: random1
      prey_40: random1
      prey_41: random1
      prey_42: random1
      prey_43: random1
      prey_44: random1
      prey_45: random1
      prey_46: random1
      prey_47: random1
      prey_48: random1
      prey_49: random1
  opp_obs_queue_len: 5

epsilon_scheduler:
  type: "logarithmic"
  start_value: 1.0
  end_value: 0.05
  decay_steps: 100

sample_ratio_scheduler:
  type: "linear"
  start_value: 1.0
  end_value: 0.3
  decay_steps: 100

critic_config:
  type: "QMIX"
  state_shape: 256
  input_dim: 25
  qmix_hidden_dim: 128
  hypernet_layers: 2
  hyper_hidden_dim: 256
  feature_extractor:
    model_type: "Custom"
    layers:
      - type: Permute
        dims: [0, 3, 1, 2]
      - type: Conv2d
        in_channels: 29
        out_channels: 32
        kernel_size: 9
        stride: 4
        padding: 4
      - type: BatchNorm2d
        num_features: 32
      - type: ReLU
      - type: Conv2d
        in_channels: 32
        out_channels: 64
        kernel_size: 4
        stride: 2
        padding: 1
      - type: ReLU
      - type: BatchNorm2d
        num_features: 64
      - type: AdaptiveAvgPool2d
        output_size: [2,2]
      - type: Flatten
  optimizer:
    type: "Adam"
    lr: 0.0005
    weight_decay: 0.0001

rollout_config:
  manager_type: "multi-thread"
  worker_type: "multi-thread"
  n_workers: 4
  n_episodes: 1000
  n_eval_episodes: 100
  traj_len: 5
  episode_limit: 500
  device: "cpu"

replaybuffer_config:
  type: "Normal"
  capacity: 50000
  traj_len: 5

trainer_config:
  type: "GraphQMIX"
  gamma: 0.95
  eval_epsilon: 0.01
  workdir: "./test/results/graph_qmix_default"
  train_device: "cpu"
  eval_device: "cpu"
  
  train_args:
    epochs: 100
    target_reward: 100
    eval_interval: 1
    batch_size: 8
    learning_times_per_epoch: 1